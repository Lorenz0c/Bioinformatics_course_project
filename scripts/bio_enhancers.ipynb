{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bio_enhancers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6892cab6e71a43fcb27c5409f7c09e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0343f74f4afd468f8b11dfbea863db2d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6727c11cf0d545418d2678ed329438c6",
              "IPY_MODEL_d00f7cbb974e41f191d649a7a536113e"
            ]
          }
        },
        "0343f74f4afd468f8b11dfbea863db2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "6727c11cf0d545418d2678ed329438c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c374a26d725348bfa4613e83c7789908",
            "_dom_classes": [],
            "description": "Downloading to datasets/fantom/...rs/GM12878.csv.xz: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 16587532,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16587532,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d811f72e70644f6a2197dabd48c5f3e"
          }
        },
        "d00f7cbb974e41f191d649a7a536113e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e1d9c8df6cf462081f354c8437e5b1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16.6M/16.6M [00:00&lt;00:00, 35.0MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7d05bcf756341dd95516d0037259c6a"
          }
        },
        "c374a26d725348bfa4613e83c7789908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d811f72e70644f6a2197dabd48c5f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e1d9c8df6cf462081f354c8437e5b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7d05bcf756341dd95516d0037259c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1e6ac94dd884d2093f8f0cb37d162e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8ab1049fcbbc4dbc84b519f391b9b41b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f82cfc1a3d314fca9eacf67b8c310cff",
              "IPY_MODEL_e5b1faef032c4a838adf360763d87a23"
            ]
          }
        },
        "8ab1049fcbbc4dbc84b519f391b9b41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f82cfc1a3d314fca9eacf67b8c310cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7fd433df40049caa9f0fc6ff16f0438",
            "_dom_classes": [],
            "description": "Downloading to datasets/fantom/.../enhancers.bed.xz: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 460128,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 460128,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9c8dc8300c1445f9a4323395db8a3f4d"
          }
        },
        "e5b1faef032c4a838adf360763d87a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fe370dd4ebb43cc8be1c28e02814e95",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 460k/460k [00:00&lt;00:00, 7.61MiB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5923ef185d549188538037df689b619"
          }
        },
        "c7fd433df40049caa9f0fc6ff16f0438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9c8dc8300c1445f9a4323395db8a3f4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fe370dd4ebb43cc8be1c28e02814e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5923ef185d549188538037df689b619": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff2a4a1826dd42b38d38e3d0ab09ab7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7587bb10c35a4b25a32c6c236e51b596",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_14b0403ae8fa4f36b66b2d5ed29f56e9",
              "IPY_MODEL_74b6f4f44abd4615aaf4ff7be279fd80"
            ]
          }
        },
        "7587bb10c35a4b25a32c6c236e51b596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "14b0403ae8fa4f36b66b2d5ed29f56e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98c0e7e527d648009cd444c3c67d3a32",
            "_dom_classes": [],
            "description": "Downloading chromosomes for genome hg38: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08512e0a20524d3db34c983b3d5283a3"
          }
        },
        "74b6f4f44abd4615aaf4ff7be279fd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c0e24bf9b82423f829de8dd7bf1d8d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [07:57&lt;00:00, 30.48s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83d0ec1b0e6d46ed96b4239b20ae710c"
          }
        },
        "98c0e7e527d648009cd444c3c67d3a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08512e0a20524d3db34c983b3d5283a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c0e24bf9b82423f829de8dd7bf1d8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83d0ec1b0e6d46ed96b4239b20ae710c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eac9ab9975ab47d089e2f358966b40a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_91399683d6e641f1b039a04b7e5492af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d99b3b9dbedb421f9912252c94d9987b",
              "IPY_MODEL_d5db4343e5694884a86669ca4360afce"
            ]
          }
        },
        "91399683d6e641f1b039a04b7e5492af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d99b3b9dbedb421f9912252c94d9987b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2c4c533a13e41f69b0bee0759aba604",
            "_dom_classes": [],
            "description": "Loading chromosomes for genome hg38: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a47cf5c5b7fd447fa6f3888823f6c4c9"
          }
        },
        "d5db4343e5694884a86669ca4360afce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_128a091c630c45b0a897da2976da46a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [00:10&lt;00:00,  1.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aac9360f093d4fd59b1967afd380b7e5"
          }
        },
        "b2c4c533a13e41f69b0bee0759aba604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a47cf5c5b7fd447fa6f3888823f6c4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "128a091c630c45b0a897da2976da46a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aac9360f093d4fd59b1967afd380b7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw4FqJEztrOL",
        "outputId": "3fe360a5-75e4-4cb6-fb94-e6e5e4f6ff16"
      },
      "source": [
        "!pip install epigenomic_dataset\n",
        "!pip install ucsc_genomes_downloader\n",
        "!pip install keras_bed_sequence\n",
        "!pip install minepy\n",
        "!pip install boruta\n",
        "!pip install extra_keras_metrics"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting epigenomic_dataset\n",
            "  Downloading epigenomic_dataset-1.2.11.tar.gz (15 kB)\n",
            "Collecting encodeproject>=1.0.19\n",
            "  Downloading encodeproject-1.0.27.tar.gz (10 kB)\n",
            "Collecting downloaders\n",
            "  Downloading downloaders-1.0.12.tar.gz (10 kB)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from epigenomic_dataset) (1.1.5)\n",
            "Collecting pybwtool>=1.0.8\n",
            "  Downloading pybwtool-1.0.8.tar.gz (4.9 kB)\n",
            "Collecting crr_labels>=1.1.1\n",
            "  Downloading crr_labels-1.1.1.tar.gz (12 kB)\n",
            "Collecting notipy_me>=1.3.23\n",
            "  Downloading notipy_me-1.3.23.tar.gz (10 kB)\n",
            "Collecting cache_decorator[all]\n",
            "  Downloading cache_decorator-2.0.6.tar.gz (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from encodeproject>=1.0.19->epigenomic_dataset) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from encodeproject>=1.0.19->epigenomic_dataset) (4.41.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (from encodeproject>=1.0.19->epigenomic_dataset) (0.5.1)\n",
            "Collecting validate_email\n",
            "  Downloading validate_email-1.3.tar.gz (4.7 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from notipy_me>=1.3.23->epigenomic_dataset) (0.8.9)\n",
            "Collecting environments_utils\n",
            "  Downloading environments_utils-1.0.3.tar.gz (3.5 kB)\n",
            "Collecting validators\n",
            "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
            "Collecting userinput\n",
            "  Downloading userinput-1.0.15.tar.gz (8.1 kB)\n",
            "Collecting sanitize_ml_labels>=1.0.16\n",
            "  Downloading sanitize_ml_labels-1.0.26.tar.gz (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->epigenomic_dataset) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->epigenomic_dataset) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->epigenomic_dataset) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->epigenomic_dataset) (1.15.0)\n",
            "Collecting compress_json\n",
            "  Downloading compress_json-1.0.4.tar.gz (4.7 kB)\n",
            "Collecting dict_hash>=1.1.16\n",
            "  Downloading dict_hash-1.1.16.tar.gz (5.3 kB)\n",
            "Collecting compress_pickle\n",
            "  Downloading compress_pickle-2.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting deflate_dict\n",
            "  Downloading deflate_dict-1.0.9.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (2.5.9)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (from cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (1.1.0)\n",
            "\u001b[33mWARNING: cache-decorator 2.0.6 does not provide the extra 'compress_json'\u001b[0m\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from dict_hash>=1.1.16->cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->dict_hash>=1.1.16->cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->dict_hash>=1.1.16->cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (57.2.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl->cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl->cache_decorator[all]->crr_labels>=1.1.1->epigenomic_dataset) (1.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->encodeproject>=1.0.19->epigenomic_dataset) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->encodeproject>=1.0.19->epigenomic_dataset) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->encodeproject>=1.0.19->epigenomic_dataset) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->encodeproject>=1.0.19->epigenomic_dataset) (2021.5.30)\n",
            "Collecting validate_version_code\n",
            "  Downloading validate_version_code-1.0.4.tar.gz (3.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from userinput->notipy_me>=1.3.23->epigenomic_dataset) (5.5.0)\n",
            "Collecting IPy\n",
            "  Downloading IPy-1.01.tar.gz (33 kB)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->userinput->notipy_me>=1.3.23->epigenomic_dataset) (0.7.0)\n",
            "Building wheels for collected packages: epigenomic-dataset, crr-labels, encodeproject, notipy-me, pybwtool, sanitize-ml-labels, cache-decorator, dict-hash, deflate-dict, compress-json, downloaders, environments-utils, userinput, IPy, validate-email, validate-version-code\n",
            "  Building wheel for epigenomic-dataset (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for epigenomic-dataset: filename=epigenomic_dataset-1.2.11-py3-none-any.whl size=16125 sha256=7a7a831a521c9976e8e039ecfcaa6394821c882817e43aeb221ac27f8b753686\n",
            "  Stored in directory: /root/.cache/pip/wheels/55/ae/00/711945f7eb139c3e7b5afd32628e468070b86698175d938b43\n",
            "  Building wheel for crr-labels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crr-labels: filename=crr_labels-1.1.1-py3-none-any.whl size=13910 sha256=a950c0755536b7f86ae1075a84fe0f203a00e5dc97e1d6915f808a45f459ea7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/35/18/9f4c037100da0b7c44bbe85ed0d0e0520d71855f8d92c399c1\n",
            "  Building wheel for encodeproject (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodeproject: filename=encodeproject-1.0.27-py3-none-any.whl size=9621 sha256=99c100c906f296fb4c807c0d91825f255013b93b648f646fb2cb787c309e3586\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/03/63/a272266e6c9c3d5ce2ccf1088508c952e91b0101650730ce44\n",
            "  Building wheel for notipy-me (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for notipy-me: filename=notipy_me-1.3.23-py3-none-any.whl size=11705 sha256=55795ee54c9075a877059bc3d00b2dbc36d10ad34c44545c435021c4e7f483bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/bf/9d/f5f2057919ffb526a6210cd9a6c6c4fb5a816f9cdef06ed3fd\n",
            "  Building wheel for pybwtool (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybwtool: filename=pybwtool-1.0.8-py3-none-any.whl size=5629 sha256=68302767ff08baa5b68ee4c65849f833a350eb47b82445d4b9ea1129007169c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/e5/be/b553ebb5521fd036db01d1210737ec5cba673e1964c7a4f22c\n",
            "  Building wheel for sanitize-ml-labels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sanitize-ml-labels: filename=sanitize_ml_labels-1.0.26-py3-none-any.whl size=7612 sha256=80700ad5e1cc9c3fb56e1602985bd7b910ab167c840b069bb17c6b5299364e93\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/65/34/2e11a0da3cf6f112da5c402e01c454be619ff85a0fb38b3018\n",
            "  Building wheel for cache-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cache-decorator: filename=cache_decorator-2.0.6-py3-none-any.whl size=24399 sha256=5ccfb22d44c9216b34cea1d63911342cb895657d842e96fdd16a3a2016909bb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/7b/98/53775478046629035f26e89cea05f14d29cf1f46ddb0851abf\n",
            "  Building wheel for dict-hash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dict-hash: filename=dict_hash-1.1.16-py3-none-any.whl size=5759 sha256=be6e7e31844be4a1e55e1bd23870f4c8c289ca66a040fa210d3e85db09f2105f\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/18/63/918f86a7c9d8829abfd4426aab36c17c6bbec5ff7d34bc2cde\n",
            "  Building wheel for deflate-dict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deflate-dict: filename=deflate_dict-1.0.9-py3-none-any.whl size=6334 sha256=97182f64a9b2c9b57f75e54a6a231e1b23497f0947348eca644e2a43a02e9f45\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/26/bc/292d8c1d3c94eefc1d6ee239603cc492d531d9e5d5ab682564\n",
            "  Building wheel for compress-json (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for compress-json: filename=compress_json-1.0.4-py3-none-any.whl size=4588 sha256=aa34134109bda00f4d2b68e439f31029650a820b6b0fad14ed2811dea71ac937\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/ef/1e/5d403c5632b0462471a8d26049d0c138134d0255ec60ce4c14\n",
            "  Building wheel for downloaders (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for downloaders: filename=downloaders-1.0.12-py3-none-any.whl size=13392 sha256=5b8e8805bb3a9a27a197959dec1b27abd0890d2d2a7be35f1183ade84a95e482\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/47/42/70ad2619cbaf8835684ce9d42e2f3a543ff5b5e3e3d2c66128\n",
            "  Building wheel for environments-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for environments-utils: filename=environments_utils-1.0.3-py3-none-any.whl size=4302 sha256=c0c8f457e83d37b647616a669d400a205088a198632937b99f92acefb5dfa123\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/c3/fb/deb4b1a451b151d5dd8431e65567a1ca256051c5870c22d993\n",
            "  Building wheel for userinput (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for userinput: filename=userinput-1.0.15-py3-none-any.whl size=8967 sha256=ff20209fa7852124a59db86d0b6b9b9671982939ed7017b6ca5a91360c0c7f34\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/dc/22/018ac346bf582d2e2255bf0ef14ec71884da8a9554f0b79b4a\n",
            "  Building wheel for IPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for IPy: filename=IPy-1.1-py3-none-any.whl size=19455 sha256=49ce72f127f43d32ea1c1d0c1c41cb52a09e8fbb98f9b584e3be3eacf435d1b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/10/df/fcb3fffa99ae69a87385e64864fc91216f9c49ef9de0e30e02\n",
            "  Building wheel for validate-email (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validate-email: filename=validate_email-1.3-py3-none-any.whl size=5481 sha256=7d4e7c28880457c3484eace29ffb7a32476ce249f92b4eac7cfc6b1a864c763c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/8f/92/c43287715852eaa75e0d8aa1941c481072b4a82c4f4975074e\n",
            "  Building wheel for validate-version-code (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validate-version-code: filename=validate_version_code-1.0.4-py3-none-any.whl size=3211 sha256=0c3786dec7c0033c88ee27c3d46d3f220ca2decbfacfadd39025cee092febe73\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/59/e0/04602a9f65f400c50f6ce322ca64a6b4edc9d84f95c9e77ef4\n",
            "Successfully built epigenomic-dataset crr-labels encodeproject notipy-me pybwtool sanitize-ml-labels cache-decorator dict-hash deflate-dict compress-json downloaders environments-utils userinput IPy validate-email validate-version-code\n",
            "Installing collected packages: deflate-dict, dict-hash, compress-pickle, compress-json, cache-decorator, validators, validate-version-code, validate-email, IPy, userinput, sanitize-ml-labels, environments-utils, encodeproject, pybwtool, notipy-me, downloaders, crr-labels, epigenomic-dataset\n",
            "Successfully installed IPy-1.1 cache-decorator-2.0.6 compress-json-1.0.4 compress-pickle-2.0.1 crr-labels-1.1.1 deflate-dict-1.0.9 dict-hash-1.1.16 downloaders-1.0.12 encodeproject-1.0.27 environments-utils-1.0.3 epigenomic-dataset-1.2.11 notipy-me-1.3.23 pybwtool-1.0.8 sanitize-ml-labels-1.0.26 userinput-1.0.15 validate-email-1.3 validate-version-code-1.0.4 validators-0.18.2\n",
            "Collecting ucsc_genomes_downloader\n",
            "  Downloading ucsc_genomes_downloader-1.1.25.tar.gz (14 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader) (4.41.1)\n",
            "Collecting dateparser\n",
            "  Downloading dateparser-1.0.0-py2.py3-none-any.whl (279 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 279 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader) (1.1.5)\n",
            "Requirement already satisfied: numba>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50.0->ucsc_genomes_downloader) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50.0->ucsc_genomes_downloader) (57.2.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50.0->ucsc_genomes_downloader) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader) (1.5.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser->ucsc_genomes_downloader) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader) (1.24.3)\n",
            "Building wheels for collected packages: ucsc-genomes-downloader\n",
            "  Building wheel for ucsc-genomes-downloader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ucsc-genomes-downloader: filename=ucsc_genomes_downloader-1.1.25-py3-none-any.whl size=15334 sha256=eaf81426723a354159864b0304a0cd92adb0179b1dee970024f6fd765216ee07\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/fb/51/265a64a75a1a9c578b34918dad6599245457559371aed39495\n",
            "Successfully built ucsc-genomes-downloader\n",
            "Installing collected packages: dateparser, ucsc-genomes-downloader\n",
            "Successfully installed dateparser-1.0.0 ucsc-genomes-downloader-1.1.25\n",
            "Collecting keras_bed_sequence\n",
            "  Downloading keras_bed_sequence-1.1.8.tar.gz (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_bed_sequence) (1.19.5)\n",
            "Requirement already satisfied: numba>=0.50 in /usr/local/lib/python3.7/dist-packages (from keras_bed_sequence) (0.51.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from keras_bed_sequence) (1.1.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras_bed_sequence) (2.5.0)\n",
            "Collecting keras_mixed_sequence>=1.0.19\n",
            "  Downloading keras_mixed_sequence-1.0.26.tar.gz (6.9 kB)\n",
            "Requirement already satisfied: ucsc_genomes_downloader>=1.1.25 in /usr/local/lib/python3.7/dist-packages (from keras_bed_sequence) (1.1.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras_mixed_sequence>=1.0.19->keras_bed_sequence) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->keras_bed_sequence) (57.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.50->keras_bed_sequence) (0.34.0)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2.23.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2018.9)\n",
            "Requirement already satisfied: regex!=2019.02.19 in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2.8.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (1.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ucsc_genomes_downloader>=1.1.25->keras_bed_sequence) (2021.5.30)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (3.1.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.34.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras_bed_sequence) (0.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->keras_bed_sequence) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->keras_bed_sequence) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras_bed_sequence) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras_bed_sequence) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras_bed_sequence) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras_bed_sequence) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras_bed_sequence) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->keras_bed_sequence) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->keras_bed_sequence) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow->keras_bed_sequence) (3.5.0)\n",
            "Building wheels for collected packages: keras-bed-sequence, keras-mixed-sequence\n",
            "  Building wheel for keras-bed-sequence (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bed-sequence: filename=keras_bed_sequence-1.1.8-py3-none-any.whl size=5760 sha256=f169899232e725ee8b3d80f9ec62f6fa1af8d157c4ec2f575e49f1a726430f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/85/9d/80f86f57c46f6d8df62caff4ecde621b1e8389f36ec9d9a90d\n",
            "  Building wheel for keras-mixed-sequence (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-mixed-sequence: filename=keras_mixed_sequence-1.0.26-py3-none-any.whl size=7448 sha256=12ac358bf2ac01a9ae198d2d40c3205b94f49b97370637712a20282bd7f1f7c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/78/760f9f738994ba17e98af73fe7c9aeaed20a179534fe163652\n",
            "Successfully built keras-bed-sequence keras-mixed-sequence\n",
            "Installing collected packages: keras-mixed-sequence, keras-bed-sequence\n",
            "Successfully installed keras-bed-sequence-1.1.8 keras-mixed-sequence-1.0.26\n",
            "Collecting minepy\n",
            "  Downloading minepy-1.2.5.tar.gz (495 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 495 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from minepy) (1.19.5)\n",
            "Building wheels for collected packages: minepy\n",
            "  Building wheel for minepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minepy: filename=minepy-1.2.5-cp37-cp37m-linux_x86_64.whl size=177534 sha256=fd9de2692ca6dff517b0ee9e4875562498df8efd2273e9cdd351e56f4b12b5e7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ea/d7/fabbfa6e294adcbc43dabca0e0158dafdd36051246992c7311\n",
            "Successfully built minepy\n",
            "Installing collected packages: minepy\n",
            "Successfully installed minepy-1.2.5\n",
            "Collecting boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from boruta) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from boruta) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.17.1->boruta) (1.0.1)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n",
            "Collecting extra_keras_metrics\n",
            "  Downloading extra_keras_metrics-2.0.1.tar.gz (8.3 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from extra_keras_metrics) (2.5.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from extra_keras_metrics) (4.4.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (3.3.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.19.5)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (1.34.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->extra_keras_metrics) (2.5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->extra_keras_metrics) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (57.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (1.32.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->extra_keras_metrics) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->extra_keras_metrics) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->extra_keras_metrics) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->extra_keras_metrics) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->extra_keras_metrics) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->extra_keras_metrics) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->extra_keras_metrics) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->extra_keras_metrics) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->extra_keras_metrics) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->extra_keras_metrics) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow->extra_keras_metrics) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->extra_keras_metrics) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow->extra_keras_metrics) (3.5.0)\n",
            "Building wheels for collected packages: extra-keras-metrics\n",
            "  Building wheel for extra-keras-metrics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for extra-keras-metrics: filename=extra_keras_metrics-2.0.1-py3-none-any.whl size=13970 sha256=0c066beda5bef105c3f6b6c69b37f913fffbde1c336b2bc517158570aa23eb49\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/de/56/ea1d10e8eaf78da501de7070181fc200ec4af3993b17d9b627\n",
            "Successfully built extra-keras-metrics\n",
            "Installing collected packages: extra-keras-metrics\n",
            "Successfully installed extra-keras-metrics-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrr17UCh1JFX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from boruta import BorutaPy\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, InputLayer, Layer\n",
        "from tensorflow.keras.layers import Conv1D, Reshape, Flatten, MaxPool1D, AveragePooling1D\n",
        "from tensorflow.keras.layers import Dropout, Concatenate, Input, ReLU, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D, Flatten\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from extra_keras_metrics import get_standard_binary_metrics\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from scipy.stats import spearmanr\n",
        "from scipy.stats import entropy\n",
        "from minepy import MINE\n",
        "\n",
        "from scipy.stats import wilcoxon\n",
        "import scipy.stats as st\n",
        "\n",
        "from typing import Dict\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "\n",
        "from keras_bed_sequence import BedSequence\n",
        "from keras_mixed_sequence import MixedSequence, VectorSequence\n",
        "\n",
        "from ucsc_genomes_downloader import Genome\n",
        "from epigenomic_dataset import load_epigenomes"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NrmUYH22aWA"
      },
      "source": [
        "**Data retrieval**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HO2LZ_HuNrU"
      },
      "source": [
        "# Window_size is the size of the regions considered for the classification.\n",
        "window_size = 256"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH8EW2eculTp"
      },
      "source": [
        "# The value assigned to the variable assembly simply indicate the uman genome. \n",
        "assembly=\"hg38\"\n",
        "\n",
        "# The cell_line indicate the type of the human cell for which the DNA is being considered.\n",
        "cell_line=\"GM12878\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFRCeRdmvefS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "6892cab6e71a43fcb27c5409f7c09e5d",
            "0343f74f4afd468f8b11dfbea863db2d",
            "6727c11cf0d545418d2678ed329438c6",
            "d00f7cbb974e41f191d649a7a536113e",
            "c374a26d725348bfa4613e83c7789908",
            "1d811f72e70644f6a2197dabd48c5f3e",
            "7e1d9c8df6cf462081f354c8437e5b1e",
            "c7d05bcf756341dd95516d0037259c6a",
            "e1e6ac94dd884d2093f8f0cb37d162e7",
            "8ab1049fcbbc4dbc84b519f391b9b41b",
            "f82cfc1a3d314fca9eacf67b8c310cff",
            "e5b1faef032c4a838adf360763d87a23",
            "c7fd433df40049caa9f0fc6ff16f0438",
            "9c8dc8300c1445f9a4323395db8a3f4d",
            "1fe370dd4ebb43cc8be1c28e02814e95",
            "f5923ef185d549188538037df689b619"
          ]
        },
        "outputId": "f853e257-bfea-4cc1-b224-386910b975ce"
      },
      "source": [
        "# Import the epigenomes and labels (originaly obtained from ENCODE and FANDOM respectively) for enanchers.\n",
        "\n",
        "enhancers_epigenomes, enhancers_labels = load_epigenomes(\n",
        "    cell_line = cell_line,\n",
        "    dataset = \"fantom\",\n",
        "    region = \"enhancers\",\n",
        "    window_size = window_size,\n",
        "    binarize = True\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6892cab6e71a43fcb27c5409f7c09e5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading to datasets/fantom/...rs/GM12878.csv.xz', layâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1e6ac94dd884d2093f8f0cb37d162e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading to datasets/fantom/.../enhancers.bed.xz', layâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p9yj8TOOOOA"
      },
      "source": [
        "# Trasform the boolean labels into integer (false->0,true->1).\n",
        "enhancers_labels['GM12878']=enhancers_labels['GM12878'].astype(int)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "h__2ufH0wjEZ",
        "outputId": "b73f9c8d-1389-482d-e3b2-c3e261aeafc1"
      },
      "source": [
        "# Examples of enhancers epigenomes (features of the BED format more the level of interanction with the given genes).\n",
        "enhancers_epigenomes.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>chrom</th>\n",
              "      <th>SMAD5</th>\n",
              "      <th>CEBPZ</th>\n",
              "      <th>MEF2C</th>\n",
              "      <th>NRF1</th>\n",
              "      <th>TAF1</th>\n",
              "      <th>STAT5A</th>\n",
              "      <th>H2AFZ</th>\n",
              "      <th>SKIL</th>\n",
              "      <th>NFIC</th>\n",
              "      <th>ETV6</th>\n",
              "      <th>NFXL1</th>\n",
              "      <th>IKZF1</th>\n",
              "      <th>H3K27ac</th>\n",
              "      <th>MTA2</th>\n",
              "      <th>CBX5</th>\n",
              "      <th>HSF1</th>\n",
              "      <th>KAT2A</th>\n",
              "      <th>IRF4</th>\n",
              "      <th>BATF</th>\n",
              "      <th>ZNF24</th>\n",
              "      <th>CTCF</th>\n",
              "      <th>NFYA</th>\n",
              "      <th>POLR2AphosphoS2</th>\n",
              "      <th>MXI1</th>\n",
              "      <th>RBBP5</th>\n",
              "      <th>ZNF143</th>\n",
              "      <th>H3K36me3</th>\n",
              "      <th>H3K9me3</th>\n",
              "      <th>JUND</th>\n",
              "      <th>FOXK2</th>\n",
              "      <th>STAT3</th>\n",
              "      <th>H3K79me2</th>\n",
              "      <th>ASH2L</th>\n",
              "      <th>REST</th>\n",
              "      <th>ATAC-seq</th>\n",
              "      <th>EZH2</th>\n",
              "      <th>GABPA</th>\n",
              "      <th>EED</th>\n",
              "      <th>PAX8</th>\n",
              "      <th>H3K27me3</th>\n",
              "      <th>...</th>\n",
              "      <th>H3K4me3</th>\n",
              "      <th>H3K9ac</th>\n",
              "      <th>IKZF2</th>\n",
              "      <th>CREM</th>\n",
              "      <th>HDAC2</th>\n",
              "      <th>KLF5</th>\n",
              "      <th>H3K4me2</th>\n",
              "      <th>RXRA</th>\n",
              "      <th>ZZZ3</th>\n",
              "      <th>SUPT20H</th>\n",
              "      <th>STAT1</th>\n",
              "      <th>ZEB1</th>\n",
              "      <th>ZNF217</th>\n",
              "      <th>NFATC1</th>\n",
              "      <th>ELK1</th>\n",
              "      <th>SPI1</th>\n",
              "      <th>DPF2</th>\n",
              "      <th>EBF1</th>\n",
              "      <th>MLLT1</th>\n",
              "      <th>TCF12</th>\n",
              "      <th>ATF7</th>\n",
              "      <th>RAD21</th>\n",
              "      <th>YBX1</th>\n",
              "      <th>TCF7</th>\n",
              "      <th>DNase-seq</th>\n",
              "      <th>EP300</th>\n",
              "      <th>CEBPB</th>\n",
              "      <th>H3K4me1</th>\n",
              "      <th>ZNF687</th>\n",
              "      <th>IRF3</th>\n",
              "      <th>TARDBP</th>\n",
              "      <th>RFX5</th>\n",
              "      <th>UBTF</th>\n",
              "      <th>CHD2</th>\n",
              "      <th>SMARCA5</th>\n",
              "      <th>ZNF384</th>\n",
              "      <th>SIN3A</th>\n",
              "      <th>E2F4</th>\n",
              "      <th>E4F1</th>\n",
              "      <th>CHD4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chrom</th>\n",
              "      <th>chromStart</th>\n",
              "      <th>chromEnd</th>\n",
              "      <th>strand</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">chr10</th>\n",
              "      <th>100006381</th>\n",
              "      <th>100006637</th>\n",
              "      <th>.</th>\n",
              "      <td>0.80</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.69</td>\n",
              "      <td>1.62</td>\n",
              "      <td>3.28</td>\n",
              "      <td>1.59</td>\n",
              "      <td>1.55</td>\n",
              "      <td>3.60</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.60</td>\n",
              "      <td>2.31</td>\n",
              "      <td>11.10</td>\n",
              "      <td>1.87</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1.06</td>\n",
              "      <td>0.54</td>\n",
              "      <td>1.71</td>\n",
              "      <td>3.16</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.51</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.10</td>\n",
              "      <td>12.11</td>\n",
              "      <td>1.03</td>\n",
              "      <td>2.22</td>\n",
              "      <td>2.68</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.94</td>\n",
              "      <td>2.45</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>8.26</td>\n",
              "      <td>4.76</td>\n",
              "      <td>1.69</td>\n",
              "      <td>2.10</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1.03</td>\n",
              "      <td>6.04</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.37</td>\n",
              "      <td>2.85</td>\n",
              "      <td>0.95</td>\n",
              "      <td>2.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.74</td>\n",
              "      <td>2.01</td>\n",
              "      <td>1.21</td>\n",
              "      <td>2.95</td>\n",
              "      <td>1.84</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.96</td>\n",
              "      <td>2.21</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.81</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100008146</th>\n",
              "      <th>100008402</th>\n",
              "      <th>.</th>\n",
              "      <td>0.69</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.61</td>\n",
              "      <td>0.85</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.46</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.63</td>\n",
              "      <td>1.54</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.37</td>\n",
              "      <td>16.34</td>\n",
              "      <td>1.37</td>\n",
              "      <td>1.60</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.79</td>\n",
              "      <td>1.70</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>...</td>\n",
              "      <td>21.93</td>\n",
              "      <td>9.63</td>\n",
              "      <td>1.27</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.48</td>\n",
              "      <td>0.92</td>\n",
              "      <td>9.13</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.38</td>\n",
              "      <td>8.03</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.79</td>\n",
              "      <td>1.86</td>\n",
              "      <td>0.35</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.94</td>\n",
              "      <td>1.53</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.23</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100014418</th>\n",
              "      <th>100014674</th>\n",
              "      <th>.</th>\n",
              "      <td>1.21</td>\n",
              "      <td>1.66</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.84</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.29</td>\n",
              "      <td>5.87</td>\n",
              "      <td>2.60</td>\n",
              "      <td>13.34</td>\n",
              "      <td>1.83</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1.63</td>\n",
              "      <td>15.68</td>\n",
              "      <td>2.22</td>\n",
              "      <td>1.99</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.33</td>\n",
              "      <td>7.58</td>\n",
              "      <td>6.84</td>\n",
              "      <td>1.39</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.68</td>\n",
              "      <td>1.14</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0.99</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.13</td>\n",
              "      <td>2.49</td>\n",
              "      <td>6.06</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.45</td>\n",
              "      <td>4.71</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.37</td>\n",
              "      <td>2.18</td>\n",
              "      <td>10.80</td>\n",
              "      <td>1.43</td>\n",
              "      <td>1.10</td>\n",
              "      <td>3.66</td>\n",
              "      <td>6.82</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.68</td>\n",
              "      <td>2.18</td>\n",
              "      <td>1.70</td>\n",
              "      <td>5.33</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.73</td>\n",
              "      <td>3.71</td>\n",
              "      <td>2.48</td>\n",
              "      <td>15.38</td>\n",
              "      <td>4.77</td>\n",
              "      <td>4.05</td>\n",
              "      <td>0.93</td>\n",
              "      <td>1.61</td>\n",
              "      <td>4.96</td>\n",
              "      <td>4.78</td>\n",
              "      <td>1.38</td>\n",
              "      <td>2.27</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.12</td>\n",
              "      <td>3.10</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.14</td>\n",
              "      <td>2.33</td>\n",
              "      <td>2.07</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100020216</th>\n",
              "      <th>100020472</th>\n",
              "      <th>.</th>\n",
              "      <td>1.16</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.49</td>\n",
              "      <td>2.60</td>\n",
              "      <td>1.43</td>\n",
              "      <td>6.45</td>\n",
              "      <td>0.76</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.73</td>\n",
              "      <td>1.53</td>\n",
              "      <td>14.42</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.40</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.15</td>\n",
              "      <td>2.29</td>\n",
              "      <td>1.46</td>\n",
              "      <td>2.70</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.50</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.19</td>\n",
              "      <td>...</td>\n",
              "      <td>1.64</td>\n",
              "      <td>4.17</td>\n",
              "      <td>1.51</td>\n",
              "      <td>1.78</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>1.64</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.92</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.09</td>\n",
              "      <td>1.34</td>\n",
              "      <td>1.63</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.09</td>\n",
              "      <td>1.10</td>\n",
              "      <td>7.55</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.60</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.79</td>\n",
              "      <td>1.45</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100043528</th>\n",
              "      <th>100043784</th>\n",
              "      <th>.</th>\n",
              "      <td>0.49</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.94</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.03</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.79</td>\n",
              "      <td>1.71</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.11</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.88</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.47</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.41</td>\n",
              "      <td>1.48</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.56</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.42</td>\n",
              "      <td>1.88</td>\n",
              "      <td>2.07</td>\n",
              "      <td>0.80</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.49</td>\n",
              "      <td>2.02</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.45</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1.42</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.22</td>\n",
              "      <td>2.02</td>\n",
              "      <td>1.12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "chrom                              SMAD5  CEBPZ  MEF2C  ...  E2F4  E4F1  CHD4\n",
              "chrom chromStart chromEnd  strand                       ...                  \n",
              "chr10 100006381  100006637 .        0.80   1.41   1.31  ...  0.89  0.83  0.93\n",
              "      100008146  100008402 .        0.69   1.37   0.33  ...  0.43  0.74  0.99\n",
              "      100014418  100014674 .        1.21   1.66   3.00  ...  0.52  0.59  1.56\n",
              "      100020216  100020472 .        1.16   1.51   0.87  ...  0.72  1.33  1.57\n",
              "      100043528  100043784 .        0.49   1.13   0.17  ...  1.22  2.02  1.12\n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "IR2zGwo3JzDq",
        "outputId": "6850fae6-4c2e-4459-9b8e-ee74c45d28ab"
      },
      "source": [
        "# Examples of enanchers labels from fantom.\n",
        "enhancers_labels.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>GM12878</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chrom</th>\n",
              "      <th>chromStart</th>\n",
              "      <th>chromEnd</th>\n",
              "      <th>strand</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">chr10</th>\n",
              "      <th>100006381</th>\n",
              "      <th>100006637</th>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100008146</th>\n",
              "      <th>100008402</th>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100014418</th>\n",
              "      <th>100014674</th>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100020216</th>\n",
              "      <th>100020472</th>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100043528</th>\n",
              "      <th>100043784</th>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   GM12878\n",
              "chrom chromStart chromEnd  strand         \n",
              "chr10 100006381  100006637 .             0\n",
              "      100008146  100008402 .             0\n",
              "      100014418  100014674 .             0\n",
              "      100020216  100020472 .             0\n",
              "      100043528  100043784 .             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "eLyyFEAtnXYO",
        "outputId": "1aadebab-c24e-40f5-d027-a62765c27345"
      },
      "source": [
        "# Create BED format dataset.\n",
        "bed_X = enhancers_epigenomes.reset_index()\n",
        "bed = bed_X[bed_X.columns[:4]]\n",
        "\n",
        "bed"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>chrom</th>\n",
              "      <th>chrom</th>\n",
              "      <th>chromStart</th>\n",
              "      <th>chromEnd</th>\n",
              "      <th>strand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chr10</td>\n",
              "      <td>100006381</td>\n",
              "      <td>100006637</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chr10</td>\n",
              "      <td>100008146</td>\n",
              "      <td>100008402</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chr10</td>\n",
              "      <td>100014418</td>\n",
              "      <td>100014674</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chr10</td>\n",
              "      <td>100020216</td>\n",
              "      <td>100020472</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chr10</td>\n",
              "      <td>100043528</td>\n",
              "      <td>100043784</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63280</th>\n",
              "      <td>chrY</td>\n",
              "      <td>7520247</td>\n",
              "      <td>7520503</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63281</th>\n",
              "      <td>chrY</td>\n",
              "      <td>7724272</td>\n",
              "      <td>7724528</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63282</th>\n",
              "      <td>chrY</td>\n",
              "      <td>7770029</td>\n",
              "      <td>7770285</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63283</th>\n",
              "      <td>chrY</td>\n",
              "      <td>7796295</td>\n",
              "      <td>7796551</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63284</th>\n",
              "      <td>chrY</td>\n",
              "      <td>8007562</td>\n",
              "      <td>8007818</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63285 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "chrom  chrom  chromStart   chromEnd strand\n",
              "0      chr10   100006381  100006637      .\n",
              "1      chr10   100008146  100008402      .\n",
              "2      chr10   100014418  100014674      .\n",
              "3      chr10   100020216  100020472      .\n",
              "4      chr10   100043528  100043784      .\n",
              "...      ...         ...        ...    ...\n",
              "63280   chrY     7520247    7520503      .\n",
              "63281   chrY     7724272    7724528      .\n",
              "63282   chrY     7770029    7770285      .\n",
              "63283   chrY     7796295    7796551      .\n",
              "63284   chrY     8007562    8007818      .\n",
              "\n",
              "[63285 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsUDzqnjxomd"
      },
      "source": [
        "# create three dictionaries, one for the epigenomes, one for the labels, and one for the bed format.\n",
        "\n",
        "epigenomes = {\n",
        "    \"enhancers\": enhancers_epigenomes\n",
        "}\n",
        "\n",
        "bed = {\n",
        "    \"enhancers\": bed\n",
        "}\n",
        "\n",
        "labels = {\n",
        "    \"enhancers\": enhancers_labels\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "ff2a4a1826dd42b38d38e3d0ab09ab7a",
            "7587bb10c35a4b25a32c6c236e51b596",
            "14b0403ae8fa4f36b66b2d5ed29f56e9",
            "74b6f4f44abd4615aaf4ff7be279fd80",
            "98c0e7e527d648009cd444c3c67d3a32",
            "08512e0a20524d3db34c983b3d5283a3",
            "6c0e24bf9b82423f829de8dd7bf1d8d4",
            "83d0ec1b0e6d46ed96b4239b20ae710c",
            "eac9ab9975ab47d089e2f358966b40a1",
            "91399683d6e641f1b039a04b7e5492af",
            "d99b3b9dbedb421f9912252c94d9987b",
            "d5db4343e5694884a86669ca4360afce",
            "b2c4c533a13e41f69b0bee0759aba604",
            "a47cf5c5b7fd447fa6f3888823f6c4c9",
            "128a091c630c45b0a897da2976da46a2",
            "aac9360f093d4fd59b1967afd380b7e5"
          ]
        },
        "id": "tqSC6A8sx6b8",
        "outputId": "00c01f9e-019f-4589-f4bc-98b8bea16068"
      },
      "source": [
        "# Retrive from the  UCSC Genome Browser the nitrogen basis sequences of the human genome. \n",
        "\n",
        "genome = Genome(assembly)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff2a4a1826dd42b38d38e3d0ab09ab7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading chromosomes for genome hg38', layout=Layout(fâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eac9ab9975ab47d089e2f358966b40a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Loading chromosomes for genome hg38', layout=Layout(flex=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HSeB1X7zsg7",
        "outputId": "a3ff33dd-3423-405d-be54-800fe2d7b5ce"
      },
      "source": [
        "# Transform the genome in a dataframe where the nitrogen basis sequences are represented throgh one hot encoding.\n",
        "\n",
        "# Return data in BED format.\n",
        "def to_bed(data:pd.DataFrame)->pd.DataFrame:\n",
        "    \"\"\"Return bed coordinates from given dataset.\"\"\"\n",
        "    return data.reset_index()[data.index.names]\n",
        "\n",
        "# One hot encode the data.\n",
        "def one_hot_encode(genome:Genome, data:pd.DataFrame, nucleotides:str=\"actg\")->np.ndarray:\n",
        "    return np.array(BedSequence(\n",
        "        genome,\n",
        "        bed=to_bed(data),\n",
        "        nucleotides=nucleotides,\n",
        "        batch_size=1\n",
        "    ))\n",
        "\n",
        "# Flatten the one hot encode representation.\n",
        "def flat_one_hot_encode(genome:Genome, data:pd.DataFrame, window_size:int, nucleotides:str=\"actg\")->np.ndarray:\n",
        "    return one_hot_encode(genome, data, nucleotides).reshape(-1, window_size*4).astype(int)\n",
        "\n",
        "# Create a dataframe from the data.\n",
        "def to_dataframe(x:np.ndarray, window_size:int, nucleotides:str=\"actg\")->pd.DataFrame:\n",
        "    return pd.DataFrame(\n",
        "        x,\n",
        "        columns = [\n",
        "            f\"{i}{nucleotide}\"\n",
        "            for i in range(window_size)\n",
        "            for nucleotide in nucleotides\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# The dataset of the genome sequences will be identifyed by the dictionary sequences.\n",
        "sequences = {\n",
        "    region: to_dataframe(\n",
        "        flat_one_hot_encode(genome, data, window_size),\n",
        "        window_size\n",
        "    )\n",
        "    for region, data in epigenomes.items()\n",
        "}            "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "B9ZkpTiB08bW",
        "outputId": "2c691d21-e425-4be4-a19a-5764336c697e"
      },
      "source": [
        "# Examples of enhancers one hot encoded sequences. \n",
        "sequences[\"enhancers\"][:5]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0a</th>\n",
              "      <th>0c</th>\n",
              "      <th>0t</th>\n",
              "      <th>0g</th>\n",
              "      <th>1a</th>\n",
              "      <th>1c</th>\n",
              "      <th>1t</th>\n",
              "      <th>1g</th>\n",
              "      <th>2a</th>\n",
              "      <th>2c</th>\n",
              "      <th>2t</th>\n",
              "      <th>2g</th>\n",
              "      <th>3a</th>\n",
              "      <th>3c</th>\n",
              "      <th>3t</th>\n",
              "      <th>3g</th>\n",
              "      <th>4a</th>\n",
              "      <th>4c</th>\n",
              "      <th>4t</th>\n",
              "      <th>4g</th>\n",
              "      <th>5a</th>\n",
              "      <th>5c</th>\n",
              "      <th>5t</th>\n",
              "      <th>5g</th>\n",
              "      <th>6a</th>\n",
              "      <th>6c</th>\n",
              "      <th>6t</th>\n",
              "      <th>6g</th>\n",
              "      <th>7a</th>\n",
              "      <th>7c</th>\n",
              "      <th>7t</th>\n",
              "      <th>7g</th>\n",
              "      <th>8a</th>\n",
              "      <th>8c</th>\n",
              "      <th>8t</th>\n",
              "      <th>8g</th>\n",
              "      <th>9a</th>\n",
              "      <th>9c</th>\n",
              "      <th>9t</th>\n",
              "      <th>9g</th>\n",
              "      <th>...</th>\n",
              "      <th>246a</th>\n",
              "      <th>246c</th>\n",
              "      <th>246t</th>\n",
              "      <th>246g</th>\n",
              "      <th>247a</th>\n",
              "      <th>247c</th>\n",
              "      <th>247t</th>\n",
              "      <th>247g</th>\n",
              "      <th>248a</th>\n",
              "      <th>248c</th>\n",
              "      <th>248t</th>\n",
              "      <th>248g</th>\n",
              "      <th>249a</th>\n",
              "      <th>249c</th>\n",
              "      <th>249t</th>\n",
              "      <th>249g</th>\n",
              "      <th>250a</th>\n",
              "      <th>250c</th>\n",
              "      <th>250t</th>\n",
              "      <th>250g</th>\n",
              "      <th>251a</th>\n",
              "      <th>251c</th>\n",
              "      <th>251t</th>\n",
              "      <th>251g</th>\n",
              "      <th>252a</th>\n",
              "      <th>252c</th>\n",
              "      <th>252t</th>\n",
              "      <th>252g</th>\n",
              "      <th>253a</th>\n",
              "      <th>253c</th>\n",
              "      <th>253t</th>\n",
              "      <th>253g</th>\n",
              "      <th>254a</th>\n",
              "      <th>254c</th>\n",
              "      <th>254t</th>\n",
              "      <th>254g</th>\n",
              "      <th>255a</th>\n",
              "      <th>255c</th>\n",
              "      <th>255t</th>\n",
              "      <th>255g</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 1024 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0a  0c  0t  0g  1a  1c  1t  ...  254c  254t  254g  255a  255c  255t  255g\n",
              "0   1   0   0   0   0   0   0  ...     0     0     1     0     0     1     0\n",
              "1   1   0   0   0   1   0   0  ...     0     0     0     1     0     0     0\n",
              "2   0   0   0   1   0   0   1  ...     1     0     0     1     0     0     0\n",
              "3   1   0   0   0   0   0   1  ...     0     0     1     0     0     1     0\n",
              "4   0   0   0   1   0   0   1  ...     1     0     0     0     0     1     0\n",
              "\n",
              "[5 rows x 1024 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9Ty0BZ32V4m"
      },
      "source": [
        "**Data pre-pocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f7KrnVb3NHa",
        "outputId": "a72f4715-6564-4ab5-d4ef-243579d5fa18"
      },
      "source": [
        "# Check the presence of missing values.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  print(\"{} data:\".format(region))\n",
        "  print(\"Total number of NaN values: {0} over {1}\".format(data.isna().values.sum(),data.values.size))\n",
        "  print(\"Max number of NaN values per feature: {0} over {1}\".format(data.isna().values.sum(axis=0).max(),data.shape[0]))\n",
        "  print(\"Max number of NaN values per sample: {0} over {1}\".format(data.isna().values.sum(axis=1).max(),data.shape[1]))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enhancers data:\n",
            "Total number of NaN values: 62 over 9619320\n",
            "Max number of NaN values per feature: 56 over 63285\n",
            "Max number of NaN values per sample: 4 over 152\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unA63fOdAjEk"
      },
      "source": [
        "# Drop the samples with more than 30 NaN values.\n",
        "for region, data in epigenomes.items():\n",
        "  index=data.isna().values.sum(axis=1)\n",
        "  index=[i for i in range(0,len(index)) if index[i]>30]\n",
        "  for i in reversed(index):\n",
        "    epigenomes[region]=data.drop(data.index[i])\n",
        "    labels[region]=labels[region].drop(labels[region].index[i])\n",
        "    sequences[region]=sequences[region].drop(sequences[region].index[i])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac3Z59bhTGh2",
        "outputId": "eb8f6f56-d4bb-4b18-a245-2f68410886e8"
      },
      "source": [
        "# Check the presence of missing values.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  print(\"{} data:\".format(region))\n",
        "  print(\"Total number of NaN values: {0} over {1}\".format(data.isna().values.sum(),data.values.size))\n",
        "  print(\"Max number of NaN values per features: {0} over {1}\".format(data.isna().values.sum(axis=0).max(),data.shape[0]))\n",
        "  print(\"Max number of NaN values per sample: {0} over {1}\".format(data.isna().values.sum(axis=1).max(),data.shape[1]))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enhancers data:\n",
            "Total number of NaN values: 62 over 9619320\n",
            "Max number of NaN values per features: 56 over 63285\n",
            "Max number of NaN values per sample: 4 over 152\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0baRc85I8d_C"
      },
      "source": [
        "# Impute the missing data with the k-NN imputer (k=5).\n",
        "# In other words, assign to each missing feature value for a given sample, the same feature value of the most \"similar\" sample.\n",
        "\n",
        "imputer = KNNImputer()\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  # Tranform the result of the imputer in a dataframe with the same columns and rows of the one in input.\n",
        "  epigenomes[region]=pd.DataFrame(imputer.fit_transform(data),columns=data.columns,index=data.index)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsR7hZmo-ZPk",
        "outputId": "7592f187-27aa-4da6-c471-74786448e615"
      },
      "source": [
        "# There should not be missing values anymore.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  print(\"{} data:\".format(region))\n",
        "  if (data.isna().values.any()):\n",
        "    print(\"missing values are still presents\")\n",
        "  else:\n",
        "    print(\"there are no more missing values\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "enhancers data:\n",
            "there are no more missing values\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0YATXUbDrL-"
      },
      "source": [
        "# normalization of the data throgh robust scaler, a version of the scaler konwn as z-score.\n",
        "\n",
        "scaler=RobustScaler()\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  # Tranform the result of the scaler in a dataframe with the same columns and rows of the one in input.\n",
        "  epigenomes[region]=pd.DataFrame(scaler.fit_transform(data),columns=data.columns,index=data.index)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX9ZIVUgdJhQ",
        "outputId": "0486599d-5ceb-4c33-b615-7e4bb13a95bc"
      },
      "source": [
        "# Print the two ratios between active and inactive samples.\n",
        "\n",
        "for region, label in labels.items():\n",
        "  active_count=len(label[(label['GM12878']==1)])\n",
        "  inactive_count=len(label[(label['GM12878']==0)])\n",
        "\n",
        "  active_ratio=active_count/active_count\n",
        "  inactive_ratio=inactive_count/active_count\n",
        "  print('ratio between active/inactive for {0} is: {1}/{2}'.format(region, active_ratio, inactive_ratio))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratio between active/inactive for enhancers is: 1.0/35.26647564469914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLbpXz9VmRuV"
      },
      "source": [
        "**Correlation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU586HELgn9x"
      },
      "source": [
        "# p-values and correlations thresholds.\n",
        "\n",
        "p_value_threshold = 0.01\n",
        "correlation_threshold = 0.05"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q9IQ2X1m4NU"
      },
      "source": [
        "# Create the sets of features uncorrelated whit the output for both the enhanchers and the promoters.\n",
        "# Initialy this sets will be empty, features will be added after the tests.\n",
        "\n",
        "uncorrelated = {}\n",
        "\n",
        "for region, _ in epigenomes.items():\n",
        "  uncorrelated[region] = set()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D29DC26EoBR4",
        "outputId": "ba01caa2-ec86-4795-961a-a5e8d1e82c8a"
      },
      "source": [
        "# Compute the Spearman correlation between the features and their outputs to find out if they are not correlated according to a monotonic function.\n",
        "# Add the uncorrelated features to the set of the region in the dictionary uncurrelated.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  for column in data.columns:\n",
        "    correlation, p_value = spearmanr(data[column].values.ravel(), labels[region].values.ravel())\n",
        "    if p_value > p_value_threshold and correlation < correlation_threshold:\n",
        "      print(\"For the {0} feature {1} dosen't seem to be correlated to the output, correlation: {2}\".format(region,column,correlation))\n",
        "      uncorrelated[region].add(column)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the enhancers feature NFYA dosen't seem to be correlated to the output, correlation: 0.0035538192219031236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqu4ccIvs79y",
        "outputId": "a0af146e-1dae-4c16-cac7-b3070516a4d7"
      },
      "source": [
        "# Compute the Maximal information coefficient to confirm that the feature previusly identified as uncurrelated to the output.\n",
        "# This test check both linear and non-linear correlation.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  for column in uncorrelated[region]:\n",
        "    mine = MINE()\n",
        "    mine.compute_score(data[column].values.ravel(), labels[region].values.ravel())\n",
        "    computed_score=mine.mic()\n",
        "    if computed_score < correlation_threshold:\n",
        "      print(\"For the {0} feature {1} dosen't seem to be correlated to the output, correlation: {2}\".format(region,column,computed_score))\n",
        "    else:\n",
        "        uncorrelated[region].remove(column)\n",
        "        print(\"For the {0} feature {1} seem to be correlated to the output, correlation: {2}\".format(region,column,computed_score))\n",
        "        print(\"Removing the feature from the set of features uncorrelated with the output\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the enhancers feature NFYA dosen't seem to be correlated to the output, correlation: 0.009955576156008636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWYdP1X4vupk"
      },
      "source": [
        "# Remove features which are not correlated to the output.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  columns_to_drop=[]\n",
        "  for column in uncorrelated[region]:\n",
        "    columns_to_drop.append(column) \n",
        "  epigenomes[region]=data.drop(columns=columns_to_drop)    \n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaFnaauMy1y-",
        "outputId": "2be62d1a-78cf-4341-ca08-7158dcddf565"
      },
      "source": [
        "# Print number of columns in the two datasets.\n",
        "for region, data in epigenomes.items():\n",
        "  print('Number of features in {0}: {1}'.format(region,len(data.columns)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features in enhancers: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_Ln0GULEgW"
      },
      "source": [
        "# redefine p-values and correlations thresholds.\n",
        "\n",
        "p_value_threshold = 0.01\n",
        "correlation_threshold = 0.95"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfWdXXMxLVsu"
      },
      "source": [
        "# Create the sets of features uncorrelated with each others for both the enhanchers and the promoters.\n",
        "# Initialy this sets will be empty, features will be added after the tests.\n",
        "\n",
        "extremely_correlated = {}\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  extremely_correlated[region]= set()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSUu1tzXL_3t"
      },
      "source": [
        "# Correlation scores will be stored in a dictionary of array of tuples (correlation score,first feature,second feature).\n",
        "\n",
        "correlation_scores={}\n",
        "\n",
        "for region,data in epigenomes.items():\n",
        "  correlation_scores[region]= []"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8OOIovWMpHn"
      },
      "source": [
        "# Compute the correlation scores.\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  columns_names=data.columns\n",
        "  for i in range(0,data.shape[1]):\n",
        "    for j in range(i+1,data.shape[1]):\n",
        "       correlation, p_value = spearmanr(data[columns_names[i]].values.ravel(), data[columns_names[j]].values.ravel())\n",
        "       # Correlation absolute value.\n",
        "       correlation = np.abs(correlation)\n",
        "       correlation_scores[region].append((correlation,columns_names[i],columns_names[j]))\n",
        "       if p_value < p_value_threshold and correlation > correlation_threshold:\n",
        "                print(\"For {0} feature {1} and feature {2} seems to be highly correlated, correlation: {3} \".format(region, columns_names[i], columns_names[j], correlation))\n",
        "                # If the two feature are highly correlated, add to the list of highly correlated features the one of the two with the lower entropy.\n",
        "                if entropy(data[columns_names[i]]) > entropy(data[columns_names[i]]):\n",
        "                    extremely_correlated[region].add(columns_names[j])\n",
        "                else:\n",
        "                    extremely_correlated[region].add(columns_names[i])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzQz0f7m_VjO"
      },
      "source": [
        "**Feature selection with Boruta.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhvOdKSL_b01"
      },
      "source": [
        "# Boruta use a random forest classifier inside its procedure.\n",
        "# This classifier is here defined as random_forest_classifier.\n",
        "random_forest_classifier=RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
        "\n",
        "# The function recive a dataset and its labels and return the classifier filtered.\n",
        "def boruta_feature_selection(X:pd.DataFrame,y:pd.DataFrame)->BorutaPy:\n",
        "  \n",
        "  # alpha is the p-value that will be used to reject of accept the features.\n",
        "  boruta_feature_selector=BorutaPy(random_forest_classifier,n_estimators='auto',verbose=2,alpha=0.05,max_iter=10,random_state=1)\n",
        "\n",
        "  boruta_feature_selector.fit(X.values, y.values.ravel())\n",
        "  \n",
        "  return boruta_feature_selector.transform(X.values)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTKfqKi_OUGW",
        "outputId": "789cf6ad-d2d3-48e7-9e54-d3442dc1d084"
      },
      "source": [
        "filtered_epigenomes={}\n",
        "\n",
        "for region, data in epigenomes.items():\n",
        "  filtered_epigenomes[region]=boruta_feature_selection(data,labels[region])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: \t1 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t2 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t3 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t4 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t5 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t6 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t7 / 10\n",
            "Confirmed: \t0\n",
            "Tentative: \t151\n",
            "Rejected: \t0\n",
            "Iteration: \t8 / 10\n",
            "Confirmed: \t98\n",
            "Tentative: \t53\n",
            "Rejected: \t0\n",
            "Iteration: \t9 / 10\n",
            "Confirmed: \t98\n",
            "Tentative: \t44\n",
            "Rejected: \t9\n",
            "\n",
            "\n",
            "BorutaPy finished running.\n",
            "\n",
            "Iteration: \t10 / 10\n",
            "Confirmed: \t98\n",
            "Tentative: \t19\n",
            "Rejected: \t9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svJvMzkaoD2a"
      },
      "source": [
        "**Holdouts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmgXRBGLoGo8"
      },
      "source": [
        "# Create a statified holdouts generator that split the data in 5 folds, using one of them as test set, and repeating the split 10 times.\n",
        "# The folds created will mantain the original percentage of samples for each class.\n",
        "number_of_splits = 8\n",
        "\n",
        "holdouts_generator = StratifiedShuffleSplit(n_splits=number_of_splits,test_size=0.2)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eSSna4-q0cJ"
      },
      "source": [
        "**Models evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOqZ0ju7o5It"
      },
      "source": [
        "# Metrics that will be used to evaluate the results.\n",
        "metrics=(\"AUPRC\", \"AUROC\", \"accuracy\", \"f1_score\", \"precision\", \"recall\")\n",
        "\n",
        "# Definition of the class weights to reduce the impact of the imbalance in the dataset.\n",
        "class_weights={0: 1, 1: 9}"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRVSfm3gqzqx"
      },
      "source": [
        "# Evaluate the nerual network passed.\n",
        "# Returns two dictionaries with the values for the metrics chosen for test and train set.\n",
        "def evaluate_nn_model(train_sequence:MixedSequence, test_sequence:MixedSequence, model:Model, model_name:str, holdout_number:int, use_feature_selection:bool,):\n",
        "\n",
        "    train_evaluation={}\n",
        "    test_evaluation={}\n",
        "\n",
        "    for metric,value in zip(model.metrics_names, model.evaluate(train_sequence, verbose=False)):\n",
        "      if metric in metrics :\n",
        "        train_evaluation[metric]=value\n",
        "\n",
        "    for metric,value in zip(model.metrics_names, model.evaluate(test_sequence, verbose=False)):\n",
        "      if metric in metrics :\n",
        "        test_evaluation[metric]=value\n",
        "\n",
        "    train_evaluation[\"run_type\"] = \"train\"\n",
        "    test_evaluation[\"run_type\"] = \"test\"\n",
        "\n",
        "    for evaluation in (train_evaluation, test_evaluation):\n",
        "        evaluation[\"model_name\"] = model_name\n",
        "        evaluation[\"holdout_number\"] = holdout_number\n",
        "\n",
        "    return [train_evaluation,test_evaluation] "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jml6XYsau8xZ"
      },
      "source": [
        "# Compute the evaluations of the metrics required for the random forest and store them in a dictionary.\n",
        "def metric_forest_evaluation(y_true:np.ndarray, y_pred:np.ndarray):\n",
        "    metrics={}\n",
        "    metrics['accuracy']=accuracy_score(y_true,y_pred)\n",
        "    metrics['AUROC']=roc_auc_score(y_true,y_pred)\n",
        "    metrics['f1_score']=f1_score(y_true,y_pred)\n",
        "    metrics['AUPRC']=average_precision_score(y_true,y_pred)\n",
        "    metrics['recall']=recall_score(y_true,y_pred)\n",
        "    metrics['precision']=precision_score(y_true,y_pred)\n",
        "\n",
        "    return metrics  "
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCmapvLexZtp"
      },
      "source": [
        "**Models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51PcVIf3xb7h"
      },
      "source": [
        "# Definition of the random forest classifier.\n",
        "\n",
        "def train_random_forest(\n",
        "  X_train:np.ndarray, X_test:np.ndarray, y_train:np.ndarray, y_test:np.ndarray, holdout_number:int, use_feature_selection:bool=True) -> Dict[str, float]:\n",
        "\n",
        "  random_forest=RandomForestClassifier(n_estimators=150,class_weight=\"balanced\",max_depth=8,min_samples_leaf=50,max_samples=0.35,n_jobs=-1,verbose=False)\n",
        "  random_forest.fit(X_train,y_train)\n",
        "\n",
        "  y_train_pred = random_forest.predict(X_train)\n",
        "  y_test_pred = random_forest.predict(X_test)\n",
        "\n",
        "  # Create a disctionary with the evaluation \n",
        "  common_informations = {\n",
        "      \"model_name\": \"Random Forest\",\n",
        "      \"holdout_number\": holdout_number,\n",
        "  }  \n",
        "\n",
        "  # Returns dictionaries of the prediction evaluation for the train and test set.\n",
        "  return [\n",
        "          {\n",
        "            **metric_forest_evaluation(y_train,y_train_pred),\n",
        "            \"run_type\": \"train\",\n",
        "            **common_informations\n",
        "          },\n",
        "          {\n",
        "            **metric_forest_evaluation(y_train,y_train_pred),\n",
        "            \"run_type\": \"test\",\n",
        "            **common_informations\n",
        "          }\n",
        "  ]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZpQMJwppzWX"
      },
      "source": [
        "# Build the sequences to give in input to the neural networks. \n",
        "\n",
        "def build_ffnn_sequence( X:np.ndarray, y:np.ndarray, batch_size=1024 ) -> MixedSequence:\n",
        "\n",
        "    return MixedSequence(\n",
        "        x={\n",
        "            \"epigenomic_data\": VectorSequence(\n",
        "                X,\n",
        "                batch_size\n",
        "            )\n",
        "        },\n",
        "        y=VectorSequence(\n",
        "            y,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def build_cnn_sequence( bed: pd.DataFrame, y: np.ndarray, genome: Genome, batch_size: int ) -> MixedSequence:\n",
        "\n",
        "    return MixedSequence(\n",
        "        x={\n",
        "            \"sequence_data\": BedSequence(\n",
        "                genome,\n",
        "                bed,\n",
        "                batch_size=batch_size,\n",
        "            )\n",
        "        },\n",
        "        y=VectorSequence(\n",
        "            y,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "    )   \n",
        "\n",
        "\n",
        "def build_mmnn_sequence( X: np.ndarray, bed: pd.DataFrame, y: np.ndarray, genome: Genome, batch_size: int) -> MixedSequence: \n",
        "\n",
        "    return MixedSequence(\n",
        "        x={\n",
        "            \"sequence_data\": BedSequence(genome, bed, batch_size=batch_size),\n",
        "            \"epigenomic_data\": VectorSequence(X,batch_size=batch_size)\n",
        "        },\n",
        "        y=VectorSequence(\n",
        "            y,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "    )       "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcfaSBlPpCJ6"
      },
      "source": [
        "# Definition and training of the multilayer feedforward neural network classifier.\n",
        "\n",
        "def train_ffnn(\n",
        "    X_train: np.ndarray,\n",
        "    X_test: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    holdout_number: int,\n",
        "    use_feature_selection: bool=True\n",
        ") -> Dict[str, float]:\n",
        "    \n",
        "    # build the sequences for the training and the evaluation.\n",
        "    train_sequence=build_ffnn_sequence(X_train,y_train)\n",
        "    test_sequence=build_ffnn_sequence(X_test,y_test)\n",
        "\n",
        "    input_layer = Input(shape=(X_train.shape[1]), name=\"epigenomic_data\")\n",
        "    hidden_layer = Dense(32, activation=\"relu\")(input_layer)\n",
        "    hidden_layer = Dropout(0.3)(hidden_layer)\n",
        "    hidden_layer = Dense(16, activation=\"relu\")(hidden_layer)\n",
        "    hidden_layer = Dropout(0.3)(hidden_layer)\n",
        "    hidden_layer = Dense(16, activation=\"relu\")(hidden_layer)\n",
        "\n",
        "    output_layer=Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "\n",
        "    ffnn=Model(inputs=input_layer,outputs=output_layer)\n",
        "\n",
        "    ffnn.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=\"nadam\",\n",
        "        metrics=get_standard_binary_metrics()\n",
        "    )\n",
        "\n",
        "    ffnn.fit(\n",
        "        train_sequence,\n",
        "        validation_data=test_sequence,\n",
        "        epochs=150,\n",
        "        batch_size=1024,\n",
        "        class_weight=class_weights,\n",
        "        verbose=False,\n",
        "        callbacks=[\n",
        "            EarlyStopping(\"loss\", mode='min', patience=3),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Return first and last layer and the evaluation of the model.\n",
        "    return input_layer, hidden_layer, evaluate_nn_model( train_sequence, test_sequence, ffnn, \"FFNN\", holdout_number, use_feature_selection )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50pnBg3J6Tgm"
      },
      "source": [
        "# Definition and training of the convolutional neural network classifier.\n",
        "\n",
        "def train_cnn(\n",
        "    bed_train:pd.DataFrame, bed_test:pd.DataFrame, y_train:np.ndarray, y_test:np.ndarray, genome:Genome, holdout_number:int, batch_size:int=1024, window_size:int=256,  use_feature_selection:bool=True) -> Dict[str, float]:\n",
        "\n",
        "    train_sequence = build_cnn_sequence(bed_train, y_train, genome, batch_size=batch_size)\n",
        "    test_sequence = build_cnn_sequence(bed_test, y_test, genome, batch_size=batch_size)\n",
        "    \n",
        "\n",
        "    input_layer = Input(shape=(window_size, 4), name=\"sequence_data\")\n",
        "    hidden_layer = Conv1D(32, kernel_size=6, activity_regularizer=regularizers.l2(0.0005), activation=\"relu\")(input_layer)\n",
        "    hidden_layer = Dropout(0.2)(hidden_layer)\n",
        "    hidden_layer = AveragePooling1D(pool_size=4, strides=2, padding='same')(hidden_layer)\n",
        "    hidden_layer = Conv1D(32, kernel_size=4, activity_regularizer=regularizers.l2(0.0005), activation=\"relu\")(hidden_layer)\n",
        "    hidden_layer = Conv1D(32, kernel_size=4, activity_regularizer=regularizers.l2(0.0005), activation=\"relu\")(hidden_layer)\n",
        "    hidden_layer = GlobalAveragePooling1D()(hidden_layer)\n",
        "    hidden_layer = Dense(64, activation=\"relu\")(hidden_layer)\n",
        "    hidden_layer = Dropout(0.3)(hidden_layer)\n",
        "    hidden_layer = Dense(32, activation=\"relu\")(hidden_layer)\n",
        "    hidden_layer = Dropout(0.2)(hidden_layer)\n",
        "    hidden_layer = Dense(16, activation=\"relu\")(hidden_layer)\n",
        "\n",
        "    output_layer=Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
        "\n",
        "    cnn=Model(inputs=input_layer,outputs=output_layer)\n",
        "\n",
        "    cnn.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=\"nadam\",\n",
        "        metrics=get_standard_binary_metrics()\n",
        "    )\n",
        "\n",
        "    cnn.fit(\n",
        "          train_sequence,\n",
        "          validation_data=test_sequence,\n",
        "          epochs=150,\n",
        "          batch_size=batch_size,\n",
        "          class_weight=class_weights,\n",
        "          verbose=False,\n",
        "          callbacks=[ \n",
        "                    EarlyStopping(\"loss\", mode='min', patience=3),\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    # Return first and last layer and the evaluation of the model.\n",
        "    return input_layer, hidden_layer, evaluate_nn_model( train_sequence, test_sequence, cnn, \"CNN\", holdout_number, use_feature_selection )\n",
        "    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMqzPZ4rztJ0"
      },
      "source": [
        "# Definition and training of the multimodal neural network classifier.\n",
        "# It is build starting from the two previous networks.\n",
        "\n",
        "def train_mmnn(\n",
        "    X_train:np.ndarray, X_test:np.ndarray, bed_train:pd.DataFrame, bed_test:pd.DataFrame, y_train:np.ndarray, y_test:np.ndarray, genome:Genome,\n",
        "    holdout_number:int, batch_size:int=1024, use_feature_selection:bool=True,\n",
        "    hidden_cnn:Layer=None, hidden_ffnn:Layer=None, input_ffnn:Layer=None, input_cnn:Layer=None\n",
        ") -> Dict[str, float]:\n",
        "\n",
        "    train_sequence = build_mmnn_sequence(X_train, bed_train, y_train, genome, batch_size=batch_size)\n",
        "    test_sequence = build_mmnn_sequence(X_test, bed_test, y_test, genome, batch_size=batch_size)\n",
        "\n",
        "    # Concatenate togheter the two previous NN.\n",
        "    concatenation_layer = Concatenate()([ hidden_ffnn,hidden_cnn ])\n",
        "\n",
        "    last_hidden_mmnn = Dense(32, activation=\"relu\")(concatenation_layer)\n",
        "    output_layer = Dense(1, activation=\"sigmoid\")(last_hidden_mmnn)\n",
        "\n",
        "    mmnn=Model(inputs=[input_ffnn,input_cnn],outputs=output_layer)\n",
        "\n",
        "    mmnn.compile(\n",
        "        optimizer=\"nadam\",\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=get_standard_binary_metrics()\n",
        "    )\n",
        "\n",
        "    mmnn.fit(\n",
        "          train_sequence,\n",
        "          validation_data=test_sequence,\n",
        "          epochs=150,\n",
        "          batch_size=batch_size,\n",
        "          class_weight=class_weights,\n",
        "          verbose=False,\n",
        "          callbacks=[ \n",
        "                    EarlyStopping(\"loss\", mode='min', patience=3),\n",
        "          ]\n",
        "    )\n",
        "\n",
        "    return evaluate_nn_model( train_sequence, test_sequence, mmnn, \"MMNN\", holdout_number, use_feature_selection )\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg16xqfn3UOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0621ae3d-17d9-4200-d94c-65bd2de35085"
      },
      "source": [
        "# Create a list to store all the computed performance.\n",
        "all_performance = {'enhancers':[]}\n",
        "\n",
        "for region, data in epigenomes.items(): \n",
        "  # Start the main loop, iterating through the holdouts.\n",
        "  for holdout_number, (train_indices, test_indices) in enumerate(holdouts_generator.split(data, labels[region])):\n",
        "        X_train, X_test = data.iloc[train_indices].values, data.iloc[test_indices].values\n",
        "        bed_train, bed_test = bed[region].iloc[train_indices], bed[region].iloc[test_indices]\n",
        "        y_train, y_test = labels[region].iloc[train_indices].values, labels[region].iloc[test_indices].values\n",
        "      \n",
        "        # Print the number of the current holdouts considered.\n",
        "        print(\"holdouts: {}\".format(holdout_number))\n",
        "\n",
        "        # Train the models defined and compute the results.\n",
        "\n",
        "        # Random forest training.\n",
        "        print(\"forest training\")\n",
        "        performance = train_random_forest(\n",
        "                      X_train, X_test, y_train.ravel(), y_test.ravel(), holdout_number\n",
        "                      )\n",
        "        all_performance[region] += performance\n",
        "\n",
        "        # Feedforward NN training.\n",
        "        print(\"ffnn training\")\n",
        "        input_ffnn, ffnn_trained, performance = train_ffnn(\n",
        "              X_train, X_test, y_train, y_test, holdout_number\n",
        "        )\n",
        "        all_performance[region]+= performance\n",
        "\n",
        "        # Convolutional NN training.\n",
        "        print(\"cnn training\")\n",
        "        input_cnn, cnn_trained, performance = train_cnn(\n",
        "              bed_train, bed_test, y_train.flatten(), y_test.flatten(), genome, holdout_number, 1024, 256\n",
        "        )\n",
        "        all_performance[region]+= performance \n",
        "\n",
        "        # Multimodal NN training.\n",
        "        print(\"mmnn training\")\n",
        "        performance = train_mmnn(\n",
        "                      X_train, X_test, bed_train, bed_test, y_train.flatten(), y_test.flatten(), genome, holdout_number, 1024,\n",
        "                      hidden_cnn=cnn_trained, hidden_ffnn=ffnn_trained, input_ffnn=input_ffnn, input_cnn=input_cnn\n",
        "                      )\n",
        "        all_performance[region]+= performance\n",
        "    \n",
        "  # We convert the computed performance list into a DataFrame\n",
        "  all_performance[region] = pd.DataFrame(all_performance[region])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "holdouts: 0\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 1\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 2\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 3\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 4\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 5\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 6\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n",
            "holdouts: 7\n",
            "forest training\n",
            "ffnn training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric F1Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric BalancedAccuracy implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric Specificity implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MissRate implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric FallOut implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py:257: UserWarning: Metric MatthewsCorrelationCoefficient implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  'consistency.' % (self.__class__.__name__,))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cnn training\n",
            "mmnn training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR8-W5cf_wrV"
      },
      "source": [
        "# remove holdout numbers and the column that indicate that the feature selection has been used.\n",
        "for performance_name,performance in all_performance.items():\n",
        "  preformance_name = performance.drop(columns=[\"holdout_number\"])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lxc8mrqaUUJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "830adf52-9615-4451-b0ff-7ee164490ca2"
      },
      "source": [
        "all_performance['enhancers']"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>AUROC</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>recall</th>\n",
              "      <th>precision</th>\n",
              "      <th>run_type</th>\n",
              "      <th>model_name</th>\n",
              "      <th>holdout_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.932626</td>\n",
              "      <td>0.931601</td>\n",
              "      <td>0.432351</td>\n",
              "      <td>0.263945</td>\n",
              "      <td>0.930516</td>\n",
              "      <td>0.281595</td>\n",
              "      <td>train</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.932626</td>\n",
              "      <td>0.931601</td>\n",
              "      <td>0.432351</td>\n",
              "      <td>0.263945</td>\n",
              "      <td>0.930516</td>\n",
              "      <td>0.281595</td>\n",
              "      <td>test</td>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.962096</td>\n",
              "      <td>0.983080</td>\n",
              "      <td>0.556095</td>\n",
              "      <td>0.652564</td>\n",
              "      <td>0.861032</td>\n",
              "      <td>0.410659</td>\n",
              "      <td>train</td>\n",
              "      <td>FFNN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.957336</td>\n",
              "      <td>0.949243</td>\n",
              "      <td>0.502762</td>\n",
              "      <td>0.533123</td>\n",
              "      <td>0.782235</td>\n",
              "      <td>0.370421</td>\n",
              "      <td>test</td>\n",
              "      <td>FFNN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.972328</td>\n",
              "      <td>0.782464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.081303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>train</td>\n",
              "      <td>CNN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.948250</td>\n",
              "      <td>0.965592</td>\n",
              "      <td>0.478918</td>\n",
              "      <td>0.596133</td>\n",
              "      <td>0.862464</td>\n",
              "      <td>0.331498</td>\n",
              "      <td>test</td>\n",
              "      <td>FFNN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>0.972426</td>\n",
              "      <td>0.766465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.077870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>train</td>\n",
              "      <td>CNN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>0.972426</td>\n",
              "      <td>0.734109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.072916</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>test</td>\n",
              "      <td>CNN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0.961484</td>\n",
              "      <td>0.987446</td>\n",
              "      <td>0.575718</td>\n",
              "      <td>0.661127</td>\n",
              "      <td>0.947708</td>\n",
              "      <td>0.413437</td>\n",
              "      <td>train</td>\n",
              "      <td>MMNN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>0.955361</td>\n",
              "      <td>0.952147</td>\n",
              "      <td>0.503078</td>\n",
              "      <td>0.580728</td>\n",
              "      <td>0.819484</td>\n",
              "      <td>0.362944</td>\n",
              "      <td>test</td>\n",
              "      <td>MMNN</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    accuracy     AUROC  f1_score  ...  run_type     model_name  holdout_number\n",
              "0   0.932626  0.931601  0.432351  ...     train  Random Forest               0\n",
              "1   0.932626  0.931601  0.432351  ...      test  Random Forest               0\n",
              "2   0.962096  0.983080  0.556095  ...     train           FFNN               0\n",
              "3   0.957336  0.949243  0.502762  ...      test           FFNN               0\n",
              "4   0.972328  0.782464  0.000000  ...     train            CNN               0\n",
              "..       ...       ...       ...  ...       ...            ...             ...\n",
              "59  0.948250  0.965592  0.478918  ...      test           FFNN               7\n",
              "60  0.972426  0.766465  0.000000  ...     train            CNN               7\n",
              "61  0.972426  0.734109  0.000000  ...      test            CNN               7\n",
              "62  0.961484  0.987446  0.575718  ...     train           MMNN               7\n",
              "63  0.955361  0.952147  0.503078  ...      test           MMNN               7\n",
              "\n",
              "[64 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrrlpKXsbULd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9326f400-81be-4eb0-ba60-dc1ab3ac75a4"
      },
      "source": [
        "# Use the Wilcoxon test to find out if the models performs similar between each other or is some outperforms the others.\n",
        "\n",
        "for preformance_name, performance in all_performance.items():\n",
        "  for outer_model in performance.model_name.unique():\n",
        "    outer_model_performance = performance[ (performance.model_name == outer_model) & (performance.run_type == \"test\") ]\n",
        "    \n",
        "    for model in performance.model_name.unique():\n",
        "       \n",
        "        # Apply the following steps only once for each couple of models (when outer_model >= model), otherwhise skip the comparison between the two model (it will be done in another iteration).\n",
        "        if outer_model >= model:\n",
        "            continue\n",
        "        \n",
        "        model_performance = performance[ (performance.model_name == model) & (performance.run_type == \"test\")]\n",
        "\n",
        "        # The comparison will be done for each one of the metrics.\n",
        "        for metric in metrics:\n",
        "            outer, inner = outer_model_performance[metric], model_performance[metric]\n",
        "\n",
        "            # Compute the p-value through the Wilcoxon test.\n",
        "            # If p-value < 0.02 one the two models performance are significatly different, and the one with the best mean is the best one.\n",
        "            _, p_value = wilcoxon(outer, inner)\n",
        "            if p_value < 0.02:\n",
        "                if np.mean(outer) > np.mean(inner):\n",
        "                    print(\"The model {0} outperforms the model {1} with p-value {2} on metric {3}.\".format(outer_model, model, p_value, metric))\n",
        "                else:\n",
        "                    print(\"The model {0} outperforms the model {1} with p-value {2} on metric {3}.\".format(model, outer_model, p_value, metric))\n",
        "            else:\n",
        "                print(\"The model {0} is statistially indistinguishiable {1} with p-value {2} on metric {3}.\".format(outer_model, model, p_value,metric))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model FFNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric AUPRC.\n",
            "The model FFNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model FFNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model FFNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric f1_score.\n",
            "The model FFNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric precision.\n",
            "The model Random Forest outperforms the model FFNN with p-value 0.011718685599768628 on metric recall.\n",
            "The model FFNN is statistially indistinguishiable MMNN with p-value 0.779434528427275 on metric AUPRC.\n",
            "The model FFNN outperforms the model MMNN with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model MMNN outperforms the model FFNN with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model MMNN outperforms the model FFNN with p-value 0.017290280592906253 on metric f1_score.\n",
            "The model MMNN outperforms the model FFNN with p-value 0.011718685599768628 on metric precision.\n",
            "The model FFNN outperforms the model MMNN with p-value 0.017153601700200603 on metric recall.\n",
            "The model Random Forest outperforms the model CNN with p-value 0.011718685599768628 on metric AUPRC.\n",
            "The model Random Forest outperforms the model CNN with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model CNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model Random Forest outperforms the model CNN with p-value 0.011718685599768628 on metric f1_score.\n",
            "The model Random Forest outperforms the model CNN with p-value 0.011718685599768628 on metric precision.\n",
            "The model Random Forest outperforms the model CNN with p-value 0.011718685599768628 on metric recall.\n",
            "The model FFNN outperforms the model CNN with p-value 0.011718685599768628 on metric AUPRC.\n",
            "The model FFNN outperforms the model CNN with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model CNN outperforms the model FFNN with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model FFNN outperforms the model CNN with p-value 0.011718685599768628 on metric f1_score.\n",
            "The model FFNN outperforms the model CNN with p-value 0.011718685599768628 on metric precision.\n",
            "The model FFNN outperforms the model CNN with p-value 0.011616044899262472 on metric recall.\n",
            "The model MMNN outperforms the model CNN with p-value 0.011718685599768628 on metric AUPRC.\n",
            "The model MMNN outperforms the model CNN with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model CNN outperforms the model MMNN with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model MMNN outperforms the model CNN with p-value 0.011718685599768628 on metric f1_score.\n",
            "The model MMNN outperforms the model CNN with p-value 0.011718685599768628 on metric precision.\n",
            "The model MMNN outperforms the model CNN with p-value 0.011718685599768628 on metric recall.\n",
            "The model MMNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric AUPRC.\n",
            "The model MMNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric AUROC.\n",
            "The model MMNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric accuracy.\n",
            "The model MMNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric f1_score.\n",
            "The model MMNN outperforms the model Random Forest with p-value 0.011718685599768628 on metric precision.\n",
            "The model Random Forest outperforms the model MMNN with p-value 0.011718685599768628 on metric recall.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/morestats.py:2879: UserWarning: Sample size too small for normal approximation.\n",
            "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH277-tl08zc"
      },
      "source": [
        "plot_results={'enhancers':{}}\n",
        "\n",
        "for performance_name,performance in all_performance.items():\n",
        "  for model in performance.model_name.unique():\n",
        "    plot_results[performance_name][model]={}\n",
        "\n",
        "    # Store the performances of the models of one of the type used in the model_performance dictionary, divided in train and test result.\n",
        "    model_performance={\n",
        "       'test':performance[(performance.model_name == model) & (performance.run_type == 'test')],\n",
        "       'train':performance[(performance.model_name == model) & (performance.run_type == 'train')],\n",
        "    }     \n",
        "\n",
        "    for metric in metrics:\n",
        "      plot_results[performance_name][model][metric]={}\n",
        "\n",
        "      for test_or_train in ['train','test']:\n",
        "\n",
        "        # Get the performances of the models for the desired metric (for test or train results). \n",
        "        performance_metric=model_performance[test_or_train][metric]\n",
        "\n",
        "        # Compute the mean.\n",
        "        mean_value=np.mean(performance_metric)\n",
        "        # Compute the intervall of confidence (errors).\n",
        "        tuple_interval_confidence=st.t.interval(alpha=0.99, df=len(performance_metric)-1, loc=mean_value, scale=st.sem(performance_metric))\n",
        "\n",
        "        # Store the results in the nested dictionary plot_results. \n",
        "        plot_results[performance_name][model][metric][test_or_train]={\n",
        "          'mean':mean_value,\n",
        "          'confidence_interval':[mean_value - tuple_interval_confidence[0],tuple_interval_confidence[1]-mean_value]\n",
        "          }"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGSPxgm5_wKl"
      },
      "source": [
        "# Convert the format of the results in dictionarys (for the means and the confidence intervals) of list for the enhancers.\n",
        "# The two list are one for the train results and one for the test results.\n",
        "\n",
        "mean_bar_enhancers={}\n",
        "confidence_bar_enhancers={}\n",
        "\n",
        "for metric in metrics:\n",
        "\n",
        "  mean_bar_enhancers[metric]={'train':[],'test':[]}\n",
        "  confidence_bar_enhancers[metric]={'train':[],'test':[]}\n",
        "\n",
        "  for test_or_train in ['train','test']:\n",
        "    confidence_bar_enhancers[metric][test_or_train]=[[],[]]\n",
        "    for model in all_performance['enhancers'].model_name.unique():\n",
        "\n",
        "      mean_bar_enhancers[metric][test_or_train].append(plot_results['enhancers'][model][metric][test_or_train]['mean'])\n",
        "      confidence_bar_enhancers[metric][test_or_train][0].append(plot_results['enhancers'][model][metric][test_or_train]['confidence_interval'][0])\n",
        "      confidence_bar_enhancers[metric][test_or_train][1].append(plot_results['enhancers'][model][metric][test_or_train]['confidence_interval'][1])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCH6pszxEtvI"
      },
      "source": [
        "# Width of the bars for the graphs to draw.\n",
        "barWidth = 0.3"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMz51338Czfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6f111be-ce0f-4eba-e26a-98a0972a0bd5"
      },
      "source": [
        "# Draw the plots of the performance for the enhancers.\n",
        "\n",
        "# Plot the bar graphs.\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(20, 20))\n",
        "models_names=[\"Forest Tree\",\"FFNN\",\"CNN\",\"MMNN\"]\n",
        "rows=metrics\n",
        "\n",
        "for row,axis in zip(rows,axes.flatten()):\n",
        "    axis.set_title(row)\n",
        "\n",
        "    # Location of labels on the x axis.\n",
        "    x_labels = np.arange(len(models_names))\n",
        "\n",
        "    # Create the bars.\n",
        "    axis.bar(x_labels - barWidth/2, mean_bar_enhancers[row]['test'], width = barWidth, color = 'blue', edgecolor = 'black', yerr=confidence_bar_enhancers[row]['test'], capsize=7, label='test')\n",
        "    axis.bar(x_labels + barWidth/2, mean_bar_enhancers[row]['train'], width = barWidth, color = 'darkorange', edgecolor = 'black', yerr=confidence_bar_enhancers[row]['train'], capsize=7, label='train')\n",
        "\n",
        "    # Lable the axis.\n",
        "    axis.set_xlabel(\"Model\")\n",
        "    axis.set_xticks(x_labels)\n",
        "    axis.set_xticklabels(models_names)\n",
        "    axis.set_ylabel(row)\n",
        "\n",
        "    axis.legend()\n",
        "plt.show()  "
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OglsDmhiFyP",
        "outputId": "f07c641f-3b0f-4725-801a-ade793dcbf92"
      },
      "source": [
        "# Report of the results:\n",
        "for metric in metrics:\n",
        "  for test_or_train in ['train','test']:\n",
        "    for i in range(0,len(models_names)):\n",
        "      print(\"medium value obtained from the {0} model for metric {1} on the {2} sets: {3}\".format(models_names[i],metric,test_or_train,mean_bar_enhancers[metric][test_or_train][i]))\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "medium value obtained from the Forest Tree model for metric AUPRC on the train sets: 0.2597411523807313\n",
            "medium value obtained from the FFNN model for metric AUPRC on the train sets: 0.6567339450120926\n",
            "medium value obtained from the CNN model for metric AUPRC on the train sets: 0.08778197225183249\n",
            "medium value obtained from the MMNN model for metric AUPRC on the train sets: 0.7003364711999893\n",
            "medium value obtained from the Forest Tree model for metric AUPRC on the test sets: 0.2597411523807313\n",
            "medium value obtained from the FFNN model for metric AUPRC on the test sets: 0.5908714979887009\n",
            "medium value obtained from the CNN model for metric AUPRC on the test sets: 0.07134357606992126\n",
            "medium value obtained from the MMNN model for metric AUPRC on the test sets: 0.5882480889558792\n",
            "medium value obtained from the Forest Tree model for metric AUROC on the train sets: 0.9282937095738975\n",
            "medium value obtained from the FFNN model for metric AUROC on the train sets: 0.9852474927902222\n",
            "medium value obtained from the CNN model for metric AUROC on the train sets: 0.7889131978154182\n",
            "medium value obtained from the MMNN model for metric AUROC on the train sets: 0.9894668608903885\n",
            "medium value obtained from the Forest Tree model for metric AUROC on the test sets: 0.9282937095738975\n",
            "medium value obtained from the FFNN model for metric AUROC on the test sets: 0.9582972601056099\n",
            "medium value obtained from the CNN model for metric AUROC on the test sets: 0.7320295497775078\n",
            "medium value obtained from the MMNN model for metric AUROC on the test sets: 0.9473075568675995\n",
            "medium value obtained from the Forest Tree model for metric accuracy on the train sets: 0.9319472426325355\n",
            "medium value obtained from the FFNN model for metric accuracy on the train sets: 0.9539434760808945\n",
            "medium value obtained from the CNN model for metric accuracy on the train sets: 0.9664958193898201\n",
            "medium value obtained from the MMNN model for metric accuracy on the train sets: 0.9623997583985329\n",
            "medium value obtained from the Forest Tree model for metric accuracy on the test sets: 0.9319472426325355\n",
            "medium value obtained from the FFNN model for metric accuracy on the test sets: 0.9494548514485359\n",
            "medium value obtained from the CNN model for metric accuracy on the test sets: 0.9659575819969177\n",
            "medium value obtained from the MMNN model for metric accuracy on the test sets: 0.9542644321918488\n",
            "medium value obtained from the Forest Tree model for metric f1_score on the train sets: 0.42829940769692876\n",
            "medium value obtained from the FFNN model for metric f1_score on the train sets: 0.5270442999899387\n",
            "medium value obtained from the CNN model for metric f1_score on the train sets: 0.04825674509629607\n",
            "medium value obtained from the MMNN model for metric f1_score on the train sets: 0.5878085270524025\n",
            "medium value obtained from the Forest Tree model for metric f1_score on the test sets: 0.42829940769692876\n",
            "medium value obtained from the FFNN model for metric f1_score on the test sets: 0.47783758863806725\n",
            "medium value obtained from the CNN model for metric f1_score on the test sets: 0.037524210289120674\n",
            "medium value obtained from the MMNN model for metric f1_score on the test sets: 0.49519122019410133\n",
            "medium value obtained from the Forest Tree model for metric precision on the train sets: 0.27872062409563375\n",
            "medium value obtained from the FFNN model for metric precision on the train sets: 0.368923369795084\n",
            "medium value obtained from the CNN model for metric precision on the train sets: 0.06559486594051123\n",
            "medium value obtained from the MMNN model for metric precision on the train sets: 0.42304275184869766\n",
            "medium value obtained from the Forest Tree model for metric precision on the test sets: 0.27872062409563375\n",
            "medium value obtained from the FFNN model for metric precision on the test sets: 0.33515841141343117\n",
            "medium value obtained from the CNN model for metric precision on the test sets: 0.05832505226135254\n",
            "medium value obtained from the MMNN model for metric precision on the test sets: 0.35745101794600487\n",
            "medium value obtained from the Forest Tree model for metric recall on the train sets: 0.9244269340974212\n",
            "medium value obtained from the FFNN model for metric recall on the train sets: 0.9267550259828568\n",
            "medium value obtained from the CNN model for metric recall on the train sets: 0.04530802374938503\n",
            "medium value obtained from the MMNN model for metric recall on the train sets: 0.9666009992361069\n",
            "medium value obtained from the Forest Tree model for metric recall on the test sets: 0.9244269340974212\n",
            "medium value obtained from the FFNN model for metric recall on the test sets: 0.8363180607557297\n",
            "medium value obtained from the CNN model for metric recall on the test sets: 0.03438395354896784\n",
            "medium value obtained from the MMNN model for metric recall on the test sets: 0.8105300888419151\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}